# -*- coding: utf-8 -*-
"""CNN for pneumonia detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W0xk0nM6dWg_uBnye7MOAbYzCRuhgPXG

#This is a CNN for Pediatric Pneumonia Detection
The dataset can be found at https://www.kaggle.com/andrewmvd/pediatric-pneumonia-chest-xray

The following function uploads our dataset.
"""

from google.colab import files
uploaded = files.upload()

"""After the file is uploaded , it is unzipped."""

!unzip archive.zip

"""We then utilise pre-existing functions and models in order to analyse the chest x-rays."""

from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
from keras.preprocessing import image
import os
import matplotlib.pyplot as plt
import cv2

img_dims = 64
batch_size = 20

"""Below is how the images are classified: we have a sequential classifier, a 3x3 convolution, a pooling layer and a flattening layer. The last two lines then condense the code."""

classifier = Sequential()
classifier.add(Conv2D(32, (3, 3), input_shape = (img_dims, img_dims, 3), activation = 'relu'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))
classifier.add(Flatten())
classifier.add(Dense(units = 128, activation = 'relu'))
classifier.add(Dense(units = 1, activation = 'sigmoid'))

"""The code below then compiles the above actions to allow for optimized accuracy."""

classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

"""The section of code below is vital for the generation of the CNNs output, as it interprets the classifications of the images."""

input_path = '/content/archive/'
train_datagen = ImageDataGenerator(rescale = 1./255,
shear_range = 0.2,
zoom_range = 0.2,
horizontal_flip = True)
test_datagen = ImageDataGenerator(rescale = 1./255)
training_set = train_datagen.flow_from_directory(directory=input_path+'train',
target_size = (img_dims, img_dims),
batch_size = batch_size,
class_mode = 'binary')
test_set = test_datagen.flow_from_directory(directory=input_path+'test',
target_size = (img_dims, img_dims),
batch_size = batch_size,
class_mode = 'binary')

"""Below is the final section of code, which has 10 epochs, meaning that the dataset is transferred through the CNN 10 times to allow for the highest possible accuracy."""

epochs = 10
hist = classifier.fit_generator(            training_set, steps_per_epoch=training_set.samples // batch_size,             epochs=epochs, validation_data=test_set,             validation_steps= test_set.samples)